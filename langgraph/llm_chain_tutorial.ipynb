{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ed1977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to a phenomenon called Rayleigh scattering. Here's a more detailed explanation:\n",
      "\n",
      "1. Sunlight is composed of different wavelengths of visible light, ranging from red (longest wavelength) to violet (shortest wavelength).\n",
      "\n",
      "2. As sunlight passes through the Earth's atmosphere, the gases in the atmosphere (primarily nitrogen and oxygen) interact with the light. This interaction is more pronounced for shorter wavelengths of light (like blue and violet).\n",
      "\n",
      "3. Rayleigh scattering occurs when the shorter wavelengths of light (blue and violet) are scattered more easily by the gas molecules in the atmosphere. This scattering effect is more pronounced for these shorter wavelengths.\n",
      "\n",
      "4. The scattered blue light is what we perceive as the color of the sky. The longer wavelengths, like red and orange, are less affected by Rayleigh scattering and tend to pass through the atmosphere more easily.\n",
      "\n",
      "5. This is why the sky appears blue during the day. At sunrise and sunset, the sunlight has to travel through more of the atmosphere, and the blue light is scattered away, allowing the longer wavelengths of red and orange to dominate, creating the beautiful warm colors of the sky.\n",
      "\n",
      "So, in summary, the sky appears blue due to the selective scattering of shorter wavelengths of light by the gases in the Earth's atmosphere, a phenomenon known as Rayleigh scattering."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = os.getenv(\"CLAUDE_MODEL\")\n",
    "model = init_chat_model(MODEL_NAME, model_provider=\"anthropic\")\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Why is the sky blue?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "# these are all equivalent ways of calling a model!\n",
    "# model.invoke(\"Hello\")\n",
    "\n",
    "# model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "# model.invoke([HumanMessage(\"Hello\")])\n",
    "\n",
    "# Streaming -> the stream method returns AIMessageChunk objects\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc365e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Why is the sky blue?', additional_kwargs={}, response_metadata={}, id='d90a77ed-3eed-4989-8987-45986e651bcf'), AIMessage(content=\"The sky appears blue due to a phenomenon called Rayleigh scattering. Here's a more detailed explanation:\\n\\n1. Sunlight is composed of a spectrum of different wavelengths of visible light. The shorter wavelengths, such as blue and violet, have higher energy compared to the longer wavelengths like red and orange.\\n\\n2. As sunlight passes through the Earth's atmosphere, the gas molecules in the air (mainly nitrogen and oxygen) interact with the light. This interaction causes the shorter wavelengths (blue and violet) to be scattered more strongly than the longer wavelengths.\\n\\n3. The scattered blue light is what we perceive as the blue color of the sky. The other wavelengths, like red and orange, pass through the atmosphere more easily.\\n\\n4. This scattering effect is more pronounced when the sun is low on the horizon, which is why sunsets and sunrises appear more reddish-orange. The light has to travel through more atmosphere, and the blue light is scattered away more effectively.\\n\\n5. If the atmosphere were made up of larger particles, the sky would appear more white or gray, as larger particles scatter all wavelengths of light equally. The small gas molecules in the atmosphere preferentially scatter the shorter, blue wavelengths.\\n\\nSo, in summary, the sky appears blue due to the physics of how light interacts with the gases in the Earth's atmosphere, a phenomenon known as Rayleigh scattering.\", additional_kwargs={}, response_metadata={'id': 'msg_01HnHHWr4Uh6MSt3UVPNjb33', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 315, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'}, id='run--1eea8c60-5b11-4d98-b409-a415daa1f525-0', usage_metadata={'input_tokens': 13, 'output_tokens': 315, 'total_tokens': 328, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import START, END, StateGraph, add_messages\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Simple chatbot graph\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "builder = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder.add_node(\"model\", call_model)\n",
    "builder.add_edge(START, \"model\")\n",
    "builder.add_edge(\"model\", END)\n",
    "\n",
    "# compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# show the graph!\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Why is the sky blue?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# call the graph by passing in the initial state\n",
    "final_state = graph.invoke({\"messages\": message})\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I love dinosaurs! My favorite dinosaur is the T-rex\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's a great choice! The T-rex is a truly impressive and iconic dinosaur. Here are some fun facts about the Tyrannosaurus rex:\n",
      "\n",
      "- T-rex was one of the largest and most powerful carnivorous dinosaurs that ever lived. It could grow up to 40 feet long and weigh over 7 tons.\n",
      "\n",
      "- It had an enormous head with long, serrated teeth that could bite with a force of over 6 tons per square inch - one of the strongest bites of any animal ever.\n",
      "\n",
      "- T-rex had small but powerful arms with two clawed fingers. While not used for attacking prey, these arms were likely used for grasping during feeding.\n",
      "\n",
      "- Despite its massive size, T-rex was an agile predator that could run at speeds up to 20 mph. Its huge head and jaws allowed it to take down even the largest plant-eating dinosaurs.\n",
      "\n",
      "- Tyrannosaurus lived during the late Cretaceous period, around 65-67 million years ago, and was one of the last great carnivorous dinosaurs before the mass extinction event.\n",
      "\n",
      "It's easy to see why the T-rex is such a beloved and iconic dinosaur. Its massive size, powerful jaws, and ferocious hunting abilities make it one of the most impressive animals to have ever roamed the Earth. I can understand why it's your favorite!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on our conversation, your favorite dinosaur is the Tyrannosaurus rex (T-rex).\n",
      "\n",
      "In your first message, you said \"Hi, I love dinosaurs! My favorite dinosaur is the T-rex.\" So you clearly stated that the T-rex is your favorite dinosaur.\n",
      "\n",
      "The T-rex is a very popular and well-known dinosaur, famous for its large size, powerful jaws, and status as one of the apex predators of the late Cretaceous period. It's easy to see why it would be a favorite among dinosaur enthusiasts.\n",
      "\n",
      "Unless you indicate otherwise, I will continue to assume that the Tyrannosaurus rex is your favorite dinosaur based on your own statement at the start of our conversation.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm afraid I don't actually know what your favorite dinosaur is. As an AI assistant, I don't have personal information about your specific preferences or favorites. I'd need you to tell me what your favorite dinosaur is in order to know the answer.\n"
     ]
    }
   ],
   "source": [
    "# Chatbot with memory state\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Messages state is a state that comes predefined with a messages (type: list of messages) and message reducers\n",
    "\n",
    "memory_graph_builder = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "memory_graph_builder.add_node(\"model\", call_model)\n",
    "memory_graph_builder.add_edge(START, \"model\")\n",
    "memory_graph_builder.add_edge(\"model\", END)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# compile the graph\n",
    "memory_graph = memory_graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# set a config to keep track of conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi, I love dinosaurs! My favorite dinosaur is the T-rex\"\n",
    "    }\n",
    "]\n",
    "\n",
    "output = memory_graph.invoke({\"messages\": message}, config)\n",
    "\n",
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()\n",
    "\n",
    "follow_up = \"What is my favorite dinosaur?\"\n",
    "follow_up = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": follow_up\n",
    "    }\n",
    "]\n",
    "\n",
    "output = memory_graph.invoke({\"messages\": follow_up}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# use a new thread id to restart the conversation\n",
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "output2 = memory_graph.invoke({\"messages\": follow_up}, config2)\n",
    "output2[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b9be620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Hi, I love dinosaurs! My favorite dinosaur is the T-rex', additional_kwargs={}, response_metadata={}, id='91cb68ed-9d89-42bf-946a-9016757774d1'), AIMessage(content=\"That's a great choice! The T-rex is a truly impressive and iconic dinosaur. Here are some fun facts about the Tyrannosaurus rex:\\n\\n- T-rex was one of the largest and most powerful carnivorous dinosaurs that ever lived. It could grow up to 40 feet long and weigh over 7 tons.\\n\\n- It had an enormous head with long, serrated teeth that could bite with a force of over 6 tons per square inch - one of the strongest bites of any animal ever.\\n\\n- T-rex had small but powerful arms with two clawed fingers. While not used for attacking prey, these arms were likely used for grasping during feeding.\\n\\n- Despite its massive size, T-rex was an agile predator that could run at speeds up to 20 mph. Its huge head and jaws allowed it to take down even the largest plant-eating dinosaurs.\\n\\n- Tyrannosaurus lived during the late Cretaceous period, around 65-67 million years ago, and was one of the last great carnivorous dinosaurs before the mass extinction event.\\n\\nIt's easy to see why the T-rex is such a beloved and iconic dinosaur. Its massive size, powerful jaws, and ferocious hunting abilities make it one of the most impressive animals to have ever roamed the Earth. I can understand why it's your favorite!\", additional_kwargs={}, response_metadata={'id': 'msg_01K1USA3HXcMK8VTjjttupzf', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 23, 'output_tokens': 304, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'}, id='run--0550bd9f-10cb-434e-b211-b4ef88f33b71-0', usage_metadata={'input_tokens': 23, 'output_tokens': 304, 'total_tokens': 327, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), HumanMessage(content='What is my favorite dinosaur?', additional_kwargs={}, response_metadata={}, id='b14342a1-106a-4371-8188-168b3657df65'), AIMessage(content='Based on our conversation, your favorite dinosaur is the Tyrannosaurus rex (T-rex).\\n\\nIn your first message, you said \"Hi, I love dinosaurs! My favorite dinosaur is the T-rex.\" So you clearly stated that the T-rex is your favorite dinosaur.\\n\\nThe T-rex is a very popular and well-known dinosaur, famous for its large size, powerful jaws, and status as one of the apex predators of the late Cretaceous period. It\\'s easy to see why it would be a favorite among dinosaur enthusiasts.\\n\\nUnless you indicate otherwise, I will continue to assume that the Tyrannosaurus rex is your favorite dinosaur based on your own statement at the start of our conversation.', additional_kwargs={}, response_metadata={'id': 'msg_01Svua7cdFxFHv3BqybAaaQC', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 337, 'output_tokens': 163, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-haiku-20240307'}, id='run--6b8526b9-bbf2-42f3-bf5f-6bbcdbaa794f-0', usage_metadata={'input_tokens': 337, 'output_tokens': 163, 'total_tokens': 500, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06dac0-0a9e-6ea6-8004-a6aa5fc681b7'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-07-31T01:16:36.142436+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06dabf-f52a-60c0-8003-24e8f3bb0284'}}, tasks=(), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "state = memory_graph.get_state(config)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb38b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I love dinosaurs! My favorite dinosaur is the T-rex\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*tips cowboy hat* Howdy there, pardner! Ain't nothin' quite like them prehistoric varmints, is there? That ol' T-rex, now that's one ferocious critter! With them big ol' teeth an' them tiny little arms, I bet it could give one heck of a bear hug, if'n it had a mind to. Now, I ain't one to pick favorites, but I gotta say, that T-rex sure is a sight to behold. Why, the way it stalked its prey, all silent-like, an' then SNAP! Just like that, it'd have its dinner. Yessir, them dinosaurs sure were a mighty impressive bunch, weren't they? Y'all got any other favorite beasties from the ol' Jurassic period? I'd be mighty pleased to hear about 'em!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my favorite dinosaur?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Well now, I reckon your favorite dinosaur would have to be the mighty T-rex! Ain't nothin' quite like that ol' king of the dinosaurs, with its massive jaws an' bone-crushin' bite. Yep, the T-rex is one impressive critter, ain't it? I can see why you'd have a soft spot for that particular prehistoric predator. They don't call it the \"tyrant lizard\" for nothin'!\n"
     ]
    }
   ],
   "source": [
    "# Chatbot with memory state and prompt templates\n",
    "from typing import TypedDict, Sequence, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START,END, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "# create a prompt template to add in a system message --> prompt template takes in 2 parameters: messages and language\n",
    "# use a messagesPlaceholder to pass all the messages in\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a {character}. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\") # this means the MessagesPlaceholder will look for a key called \"messages\" in the state\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a custom class that has the parameters our prompt_template uses\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    character: str\n",
    "\n",
    "memory_graph_builder = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "memory_graph_builder.add_node(\"model\", call_model)\n",
    "memory_graph_builder.add_edge(START, \"model\")\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# compile the graph\n",
    "memory_graph = memory_graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# set a config to keep track of conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi, I love dinosaurs! My favorite dinosaur is the T-rex\"\n",
    "    }\n",
    "]\n",
    "\n",
    "character = \"cowboy\"\n",
    "\n",
    "output = memory_graph.invoke({\"messages\": message, \"character\": character}, config)\n",
    "\n",
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()\n",
    "\n",
    "follow_up = \"What is my favorite dinosaur?\"\n",
    "follow_up = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": follow_up\n",
    "    }\n",
    "]\n",
    "\n",
    "# Note: the entire state is persisted so for future messages we can omit the \"character\" parameter as long as we don't want to change it\n",
    "output = memory_graph.invoke({\"messages\": follow_up, \"character\": character}, config)\n",
    "output[\"messages\"][-2].pretty_print()\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aeae00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of trimming messages: [SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='I like moose tracks ice cream', additional_kwargs={}, response_metadata={}), AIMessage(content='nice', additional_kwargs={}, response_metadata={}), HumanMessage(content='My favorite dinosaur is parasaurolophus', additional_kwargs={}, response_metadata={}), AIMessage(content='me too! roar!', additional_kwargs={}, response_metadata={})]\n",
      "Trimmed messages: [SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}, id='f12a68ac-146a-4a46-bd45-32a39a777b5f'), HumanMessage(content='I like moose tracks ice cream', additional_kwargs={}, response_metadata={}, id='06ad1fcf-bb74-4aaf-b77d-6cf865880d67'), AIMessage(content='nice', additional_kwargs={}, response_metadata={}, id='fd3db649-d05d-44d2-9e5f-0fe0ee6bf718'), HumanMessage(content='My favorite dinosaur is parasaurolophus', additional_kwargs={}, response_metadata={}, id='ffceb355-6103-4ddc-ac80-410465695aff'), AIMessage(content='me too! roar!', additional_kwargs={}, response_metadata={}, id='628bb074-dc2e-46b1-8a62-06da7153f7d6')]\n",
      "PROMPT messages=[SystemMessage(content='You talk like a pirate. Answer all questions to the best of your ability.', additional_kwargs={}, response_metadata={}), SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}, id='f12a68ac-146a-4a46-bd45-32a39a777b5f'), HumanMessage(content='My favorite dinosaur is parasaurolophus', additional_kwargs={}, response_metadata={}, id='ffceb355-6103-4ddc-ac80-410465695aff'), AIMessage(content='me too! roar!', additional_kwargs={}, response_metadata={}, id='628bb074-dc2e-46b1-8a62-06da7153f7d6'), HumanMessage(content=\"Hi there! What's my name? Tell me a story about my favorite dinosuar\", additional_kwargs={}, response_metadata={}, id='ebee6531-f0d9-427d-afe8-872dab753936')]\n",
      "|Av|ast|, me hearty|! Ye haven|'t share|d |yer name with| me yet,| so| I be| cal|lin' ye \"|me| frien|d\" for now|. As| fer| |yer favorite dinosaur|, the| paras|aurolophus|,| let| me| spin| ye a tale| of this| majestic beast|!|\n",
      "\n",
      "Picture| this,| me buc|ko -| a l|ush, prehistoric| landscape|, where tow|ering f|erns an|d ancient| trees s|way in the warm| breeze.| Suddenly, a magnificent| creature emerges from| the underg|rowth, its| distinctive| c|rest rising| high| above its head.| This| be| the parasaurol|ophus, a| herb|ivore| with a remarkable| adaptation| that| set| it apart from its| |kin.|\n",
      "\n",
      "Ye| see, that| tall|, hollow| c|rest weren|'t just fer| show.| N|ay, it serve|d as| a reson|ating chamber, allow|in' the paras|aurolophus| to project| its mighty calls| across| the lan|d.| Imagine the thunder|ous roars| ech|oin|' through the valleys|,| w|arn|in' other| dinosaurs of its| presence an|d cal|lin' to| its| h|erd. |\n",
      "\n",
      "This| noble| creature use|d its crest fer| more| than just communication|,| though. When| danger| lur|ked, the| parasauroloph|us coul|d t|ilt| its head and use| that| impressive| structure| as| a weapon|, bas|hin' any| would-be pre|dators that| dared to| thre|aten it| or| its young.| Truly|, it| was a force| to be reck|oned with in| the ancient| world.\n",
      "\n",
      "So|,| me| friend, what| |do ye think of this| tale of| the mighty| parasauroloph|us? I hope| it|'s given| ye a newf|ound appreciation fer| |yer favorite |dino.| Now|, tell me,| what other| adventures| woul|d ye like to hear| about in| this prehistoric| realm?||"
     ]
    }
   ],
   "source": [
    "# Managing conversation history\n",
    "# Add a step that limits the size of the messages we are passing in\n",
    "# to prevent overflowing the context window\n",
    "# do this before the prompt template but a\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=count_tokens_approximately,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm Deena\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like moose tracks ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"My favorite dinosaur is parasaurolophus\"),\n",
    "    AIMessage(content=\"me too! roar!\"),\n",
    "]\n",
    "\n",
    "print(f\"Example of trimming messages: {trimmer.invoke(messages)}\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a {character}. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\") # this means the MessagesPlaceholder will look for a key called \"messages\" in the state\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create a custom class that has the parameters our prompt_template uses\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    character: str\n",
    "\n",
    "memory_graph_builder = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    # First, trim messages\n",
    "    trimmed_messsages = trimmer.invoke(state[\"messages\"])\n",
    "\n",
    "    print(f\"Trimmed messages: {trimmer.invoke(messages)}\")\n",
    "    # Then, create prompt with the trimmed messages\n",
    "    prompt = prompt_template.invoke({\n",
    "        \"messages\": trimmed_messsages, \"character\": state[\"character\"]\n",
    "    })\n",
    "\n",
    "    print(\"PROMPT\", prompt)\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "memory_graph_builder.add_node(\"model\", call_model)\n",
    "memory_graph_builder.add_edge(START, \"model\")\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# compile the graph\n",
    "memory_graph = memory_graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "query = \"Hi there! What's my name? Tell me a story about my favorite dinosuar\"\n",
    "character = \"pirate\"\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "\n",
    "# output = memory_graph.invoke(\n",
    "#     {\n",
    "#         \"messages\": input_messages, \n",
    "#         \"character\": character\n",
    "#     },\n",
    "#     config\n",
    "# )\n",
    "\n",
    "# after trimming, the trimmed messages don't include the part about the user name\n",
    "# output[\"messages\"][-1].pretty_print()\n",
    "\n",
    "for chunk, meta_data in memory_graph.stream(\n",
    "    {\n",
    "        \"messages\": input_messages,\n",
    "        \"character\": character\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage): # Filter to show only the model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
